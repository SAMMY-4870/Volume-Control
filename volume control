import cv2
import mediapipe as mp
import numpy as np
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume

# Initialize MediaPipe Hand module
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)
mp_drawing = mp.solutions.drawing_utils

# Initialize Pycaw for volume control
def initialize_volume_control():
    devices = AudioUtilities.GetSpeakers()
    interface = devices.Activate(
        IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
    volume = cast(interface, POINTER(IAudioEndpointVolume))
    volume_range = volume.GetVolumeRange()
    return volume, volume_range

volume, volume_range = initialize_volume_control()
min_vol = volume_range[0]
max_vol = volume_range[1]

# Initialize video capture
cap = cv2.VideoCapture(1)

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break

    # Flip the frame horizontally for a later selfie-view display
    frame = cv2.flip(frame, 1)

    # Convert the BGR image to RGB
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Process the frame and detect hands
    results = hands.process(rgb_frame)

    # Design elements
    height, width, _ = frame.shape
    volume_bar_height = 400
    volume_bar_width = 50
    volume_bar_x = width - 100
    volume_bar_y = (height - volume_bar_height) // 2

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Get coordinates of the thumb tip and index finger tip
            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]

            thumb_tip_coords = np.array([thumb_tip.x * width, thumb_tip.y * height]).astype(int)
            index_tip_coords = np.array([index_tip.x * width, index_tip.y * height]).astype(int)

            # Calculate the distance between the thumb tip and index finger tip
            distance = np.linalg.norm(thumb_tip_coords - index_tip_coords)

            # Map the distance to the volume range
            vol = np.interp(distance, [30, 200], [min_vol, max_vol])
            volume.SetMasterVolumeLevel(vol, None)

            # Calculate volume percentage
            vol_percentage = np.interp(distance, [30, 200], [0, 100])

            # Draw design elements
            # Circle around the hand's detected area
            cv2.circle(frame, tuple(index_tip_coords), 15, (255, 0, 255), -1)
            cv2.circle(frame, tuple(thumb_tip_coords), 15, (255, 0, 255), -1)
            cv2.line(frame, tuple(thumb_tip_coords), tuple(index_tip_coords), (255, 0, 255), 3)

            # Volume bar background
            cv2.rectangle(frame, (volume_bar_x, volume_bar_y), 
                          (volume_bar_x + volume_bar_width, volume_bar_y + volume_bar_height), 
                          (255, 255, 255), 3)

            # Current volume level
            vol_level = np.interp(distance, [30, 200], [volume_bar_height, 0])
            cv2.rectangle(frame, (volume_bar_x, int(volume_bar_y + vol_level)), 
                          (volume_bar_x + volume_bar_width, volume_bar_y + volume_bar_height), 
                          (255, 0, 0), -1)

            # Display volume percentage
            cv2.putText(frame, f'Volume: {int(vol_percentage)}%', 
                        (volume_bar_x - 100, volume_bar_y - 20), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)

    # Display the resulting frame
    cv2.imshow('Hand Volume Control codewithashutosh', frame)

    if cv2.waitKey(5) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
